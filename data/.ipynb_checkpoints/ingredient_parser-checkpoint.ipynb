{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "pd.options.display.max_rows=500\n",
    "from IPython.display import clear_output, display\n",
    "from fuzzywuzzy import fuzz\n",
    "from pymongo import MongoClient\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spoonacular API (through RapidAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://spoonacular-recipe-food-nutrition-v1.p.rapidapi.com/recipes/parseIngredients\"\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': os.getenv(\"SPOON_API_KEY\"), \n",
    "    'content-type': \"application/x-www-form-urlencoded\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google authentication + youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"client_secret.json\"\n",
    "\n",
    "# check if previously saved credentials exist \n",
    "if os.path.exists(\"credentials.txt\"):\n",
    "    credentials = Credentials.from_authorized_user_file('credentials.txt')\n",
    "\n",
    "# gather new credentials & write to file\n",
    "else:\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file, scopes)\n",
    "    creds = flow.run_console()\n",
    "\n",
    "    creds_data = {\n",
    "        \"token\": creds.token,\n",
    "        \"refresh_token\": creds.refresh_token,\n",
    "        \"token_uri\": creds.token_uri,\n",
    "        \"client_id\": creds.client_id,\n",
    "        \"client_secret\": creds.client_secret,\n",
    "        \"scopes\": creds.scopes,\n",
    "    }\n",
    "\n",
    "    del creds_data[\"token\"]\n",
    "\n",
    "    with open(\"credentials.txt\", \"w\") as outfile:\n",
    "        json.dump(creds_data, outfile)\n",
    "\n",
    "    print(\"credentials saved\")\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "api_service_name, api_version, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mongoDB configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "db = client.desserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get new uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids of uploads that have already been processed\n",
    "upload_ids = db.videos.distinct('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up channel ids\n",
    "hanse = 'UCZTavrg2A43lQMWxiK3yu7g'\n",
    "cookingtree = 'UCtby6rJtBGgUm-2oD_E7bzw'\n",
    "hida = 'UCcp9uRaBwInxl_SZqGRksDA'\n",
    "\n",
    "channels = [hanse, cookingtree, hida]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more new videos\n",
      "no more new videos\n",
      "no more new videos\n"
     ]
    }
   ],
   "source": [
    "newUploads = pd.DataFrame()\n",
    "\n",
    "# go through each channel, appending new uploads to newUploads dataframe\n",
    "for channel in channels:\n",
    "    request = youtube.channels().list(\n",
    "        part=\"contentDetails,snippet\",\n",
    "        id=channel\n",
    "    )\n",
    "    response = request.execute()\n",
    "    uploadsId = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    \n",
    "    hasNext = True\n",
    "    nextPage = ''\n",
    "    \n",
    "    # paginate through results\n",
    "    while hasNext:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"contentDetails, snippet\",\n",
    "            playlistId=uploadsId,\n",
    "            pageToken=nextPage\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos = pd.json_normalize(response['items'])\n",
    "        \n",
    "        # check if video is a new upload\n",
    "        for i in videos.index:\n",
    "            if videos.loc[i,'contentDetails.videoId'] in upload_ids:\n",
    "                print(\"no more new videos\")\n",
    "                hasNext = False\n",
    "                break\n",
    "            else: \n",
    "                newUploads = newUploads.append(videos.loc[i])\n",
    "        try:\n",
    "            nextPage = response['nextPageToken']\n",
    "        except:\n",
    "            hasNext = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newUploads.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse out foreign language from titles and other miscellaneous things\n",
    "def format_title(x):\n",
    "    x = re.sub(r'[^a-zA-Z0-9\\,()| \\-]', '', x)\n",
    "    x = re.sub(r'^,|[^a-zA-Z]\\,','',x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.replace(\"()\", \"\").replace(\"( )\", \"\").replace(\"Cooking ASMR\",\"\")\n",
    "    x = x.replace(\"()\", \"\").replace(\"( )\", \"\")\n",
    "    x = x.strip()\n",
    "    \n",
    "    if x == '#NAME?':\n",
    "        x = \"unknown\"\n",
    "    else:\n",
    "        try:\n",
    "            if math.isnan(x):\n",
    "                x = \"unknown\"\n",
    "        except:\n",
    "            pass\n",
    "    return x\n",
    "\n",
    "newUploads['snippet.title'] = newUploads['snippet.title'].apply(lambda x: format_title(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for detecting plurality\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to filter out instructional steps\n",
    "def filterOutSteps(item): \n",
    "    if re.search(r'\\b\\d[.]', item) or re.search(r'\\b\\d[)]', item):\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to filter out items that are unlikely to be ingredients\n",
    "def filterOutIngred(item): \n",
    "    if len(item)<3 or len(item)>50:\n",
    "        return False\n",
    "    elif re.search('[a-zA-Z]{3,}', item) and re.search(r'\\b\\d+[a-zA-z| ]', item) :\n",
    "        return True\n",
    "    elif item in ingredList:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to clean the parsed out ingredient names\n",
    "def cleanParsed(item):\n",
    "    if item['name'] == '':\n",
    "         item['name'] = re.sub(r'\\d[a-zA-Z]?', '', item['original']).strip()    \n",
    "    \n",
    "    # for catching typos\n",
    "    elif ingredDf[0].apply(lambda x: fuzz.ratio(x,item['name'])).max() >= 80:\n",
    "        item['name'] = ingredDf[0][ingredDf[0].apply(lambda x: fuzz.ratio(x,item['name'])).idxmax(axis=0)]\n",
    "        \n",
    "    # for phrase-like ingredients\n",
    "    cleaned_names = list(ingredDf[ingredDf[0].apply(lambda x: True if x in item['name'] else False)][0])\n",
    "    if(cleaned_names):\n",
    "        item['name'] = max(cleaned_names,key=len)\n",
    "\n",
    "    # for eliminating plurality\n",
    "    try:\n",
    "        if p.singular_noun(item['name']):\n",
    "            item['name'] = p.singular_noun(item['name'])\n",
    "    except:\n",
    "        print(item['name'])\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to filter out parsed items that are unlikely to be ingredients\n",
    "def filterParsed(item):\n",
    "    if len(item['originalName']) < 3 or 'pan' in item['original']:\n",
    "        return False\n",
    "    elif item['name'] not in ingredList:\n",
    "        print(item['name'])\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of ingredients from local file\n",
    "ingredDf = pd.read_csv('ingredList.csv',header=None)\n",
    "ingredList = list(ingredDf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ingredient index from mongodb -- must continue to build upon this and then upsert what's in the database\n",
    "IngredientIndex = pd.DataFrame(list(db.ingredients.find())).set_index('name').drop(columns=['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterIngredientNames = []\n",
    "masterIngredientDicts = []\n",
    "newRecipe = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  1\n",
      "cm round mold\n",
      "cmhario\n",
      "cmiwaki\n"
     ]
    }
   ],
   "source": [
    "# iterate through each newly uploaded video and parse out its ingredients\n",
    "for i in range(len(newUploads)):\n",
    "    clear_output(wait=True)\n",
    "    print(\"index: \", i)\n",
    "    newRecipe = True\n",
    "    \n",
    "    # prepare structures to collect recipe info\n",
    "    ingredientNames = []\n",
    "    ingredientDict = {}\n",
    "    \n",
    "    # get ingredient section, if exists\n",
    "    desc = newUploads['snippet.description'][i].lower()\n",
    "    if \"ingredient\" in desc:\n",
    "        section = desc.split(\"ingredient\",1)[1] \n",
    "    else:\n",
    "        print(\"error at index\",i)\n",
    "        masterIngredientDicts.append(ingredientDict)\n",
    "        masterIngredientNames.append(ingredientNames)\n",
    "        continue\n",
    "    \n",
    "    # format out foreign language / some symbols -- account for fractions\n",
    "    formatted = re.sub(r'[^a-zA-Z| |0-9|\\n|,|\\+|\\|.|/|\\(|\\)]', '', section)\n",
    "    formatted = re.sub(r'/[^0-9]', '',formatted)\n",
    "    \n",
    "    # filter out instructional steps\n",
    "    ingredients = re.split('\\n',formatted)\n",
    "    ingredients = list(filter(filterOutSteps, ingredients))\n",
    "    newLine = \"\\n\"\n",
    "    ingredients = newLine.join(ingredients)\n",
    "\n",
    "    # break up multi-line ingredients and filter out invalid ones\n",
    "    ingredients = re.split(',|\\n|\\+|\\(|\\)',ingredients)\n",
    "    ingredients = list(map(lambda x: x.strip(),ingredients))\n",
    "    ingredients = list(filter(filterOutIngred, ingredients))\n",
    "    ingredients = newLine.join(ingredients)\n",
    "    \n",
    "    # call spoonacular API to parse ingredients\n",
    "    payload = {'ingredientList': ingredients, 'servings': 1}\n",
    "    response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "    data = response.json()   \n",
    "    \n",
    "    # cleaning\n",
    "    data = list(map(cleanParsed,data))\n",
    "    \n",
    "    # apply another filter\n",
    "    dataTest = list(filter(filterParsed, data))\n",
    "\n",
    "    # iterate through each entry returned (each ingredient parsed out)\n",
    "    for ingredient in dataTest:\n",
    "        ingredientName = ingredient['name']\n",
    "\n",
    "        # check if ingredient has been used in recipe before (if so, then aggregate)\n",
    "        if ingredientName in ingredientDict.keys():    \n",
    "            unitName = ingredient['unitShort']\n",
    "            amount = ingredient['amount']\n",
    "\n",
    "            if unitName in ingredientDict[ingredientName].keys():\n",
    "                ingredientDict[ingredientName][unitName] += amount\n",
    "            else:\n",
    "                ingredientDict[ingredientName][unitName] = amount\n",
    "       \n",
    "        # if new ingredient, create new entry in recipe\n",
    "        else:\n",
    "            ingredientInfo = dict((k, ingredient[k]) for k in ('amount', 'unitShort'))\n",
    "            ingredientNames.append(ingredientName)\n",
    "\n",
    "            unitName = ingredientInfo['unitShort']\n",
    "            amount = ingredientInfo['amount']\n",
    "\n",
    "            ingredientDict[ingredientName] = dict()\n",
    "            ingredientDict[ingredientName][unitName] = amount\n",
    "          \n",
    "        # update the master ingredient index \n",
    "        if ingredientName not in list(IngredientIndex.index):\n",
    "            IngredientIndex.loc[ingredientName, 'count'] = 1\n",
    "            try:\n",
    "                IngredientIndex.loc[ingredientName, 'aisle'] = ingredient['aisle']\n",
    "            except:\n",
    "                IngredientIndex.loc[ingredientName, 'aisle'] = \"Other\"\n",
    "                \n",
    "        elif newRecipe:\n",
    "            IngredientIndex.loc[ingredientName, 'count'] += 1\n",
    "            newRecipe = False\n",
    "            \n",
    "    masterIngredientDicts.append(ingredientDict)\n",
    "    masterIngredientNames.append(ingredientNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add ingredient details and names to dataframe\n",
    "newUploads['ingredientDetails'] = masterIngredientDicts\n",
    "newUploads['ingredientNames'] = masterIngredientNames\n",
    "\n",
    "# only keep those that had ingredients\n",
    "newUploads = newUploads[newUploads['ingredientNames'].apply(lambda x: True if len(x)!= 0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IngredientIndex.reset_index(inplace=True)\n",
    "IngredientIndex.columns = ['name','count','aisle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# pull out key columns & rename\n",
    "videoDf = newUploads[['snippet.resourceId.videoId','snippet.publishedAt','snippet.title','snippet.channelTitle','ingredientNames','ingredientDetails']]\n",
    "\n",
    "videoDf.rename(columns={'snippet.resourceId.videoId':\n",
    "                      'id', 'snippet.publishedAt':'published', 'snippet.title':'title',\n",
    "                      'snippet.channelTitle':'channel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1129af6c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert into mongodb\n",
    "videos = db.videos\n",
    "videoDict = videoDf.to_dict(orient = 'records')\n",
    "videos.insert_many(videoDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear existing ingredient index\n",
    "ingredients = db.ingredients\n",
    "ingredients.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1103100c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert updated ingredient index into mongodb\n",
    "ingredientDict = IngredientIndex.to_dict(orient = 'records')\n",
    "ingredients.insert_many(ingredientDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
