{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "pd.options.display.max_rows=500\n",
    "from IPython.display import clear_output, display\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'AIzaSyB_vX0yFLav3NLkbI3EAlY8KTz2RZsKMJg'\n",
    "# spoon = '7f343a652amshe6df33eb17b041bp115419jsn1277b90e4385'\n",
    "# api = sp.API(spoon)\n",
    "url = \"https://spoonacular-recipe-food-nutrition-v1.p.rapidapi.com/recipes/parseIngredients\"\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"spoonacular-recipe-food-nutrition-v1.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"7f343a652amshe6df33eb17b041bp115419jsn1277b90e4385\",\n",
    "    'content-type': \"application/x-www-form-urlencoded\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API setup / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=999581980907-6fnrj7p5dtvg5j1ctajn996f6qj90q57.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.readonly&state=DqBOt7d0ToUQUUOWnrpwC4evc9M27y&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/zQEo-0ONiZeTWiFHGnUm-3-0Gh2WEBz6qHl58TPhVgdOLQQC1ZRHZjM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "# *DO NOT* leave this option enabled in production.\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"client_secret.json\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file, scopes)\n",
    "credentials = flow.run_console()\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get youtube channel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanse = 'UCZTavrg2A43lQMWxiK3yu7g'\n",
    "cookingtree = 'UCtby6rJtBGgUm-2oD_E7bzw'\n",
    "hida = 'UCcp9uRaBwInxl_SZqGRksDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = youtube.channels().list(\n",
    "    part=\"contentDetails,snippet\",\n",
    "    id=hida\n",
    ")\n",
    "response = request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HidaMari Cooking'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['items'][0]['snippet']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadsId = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploads = pd.read_csv('uploads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "newUploads = pd.DataFrame()\n",
    "hasNext = True\n",
    "nextPage = ''\n",
    "\n",
    "# later --  build in logic that uses environment variable since_date\n",
    "# loop through each new page of uploads and stops if posted prior to since_date\n",
    "\n",
    "while hasNext:\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"contentDetails, snippet\",\n",
    "        playlistId=uploadsId,\n",
    "        pageToken=nextPage\n",
    "    )\n",
    "    response = request.execute()\n",
    "    videos = pd.json_normalize(response['items'])\n",
    "\n",
    "    for i in videos.index:\n",
    "        if videos.loc[i,'id'] in list(uploads.id):\n",
    "#                 uploads = pd.concat([uploads,newUploads])\n",
    "                uploads.reset_index(drop=True, inplace=True)\n",
    "#                 uploads.to_csv('uploads.csv', index=False)\n",
    "                print(\"updated and overwritten csv file\")\n",
    "#                 retun uploads\n",
    "        else: \n",
    "            newUploads = newUploads.append(videos.loc[i])\n",
    "    try:\n",
    "        nextPage = response['nextPageToken']\n",
    "    except:\n",
    "        hasNext = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploads = pd.concat([uploads,newUploads])\n",
    "uploads.reset_index(drop=True, inplace=True)\n",
    "uploads.to_csv('uploads.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_title(x):\n",
    "    x = re.sub(r'[^a-zA-Z0-9\\,()| \\-]', '', x)\n",
    "    x = re.sub(r'^,|[^a-zA-Z]\\,','',x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.replace(\"()\", \"\").replace(\"( )\", \"\").replace(\"Cooking ASMR\",\"\")\n",
    "    x = x.replace(\"()\", \"\").replace(\"( )\", \"\")\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "uploads['snippet.title'] = uploads['snippet.title'].apply(lambda x: format_title(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutSteps(item): \n",
    "    if re.search(r'\\b\\d[.]', item) or re.search(r'\\b\\d[)]', item):\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutIngred(item): \n",
    "    if len(item)<3 or len(item)>50:\n",
    "        return False\n",
    "    elif re.search('[a-zA-Z]{3,}', item) and re.search(r'\\b\\d+[a-zA-z| ]', item) :\n",
    "        return True\n",
    "    elif item in ingredList:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanParsed(item):\n",
    "    if item['name'] == '':\n",
    "         item['name'] = re.sub(r'\\d[a-zA-Z]?', '', item['original']).strip()    \n",
    "    \n",
    "    # for catching typos\n",
    "    elif ingredDf[0].apply(lambda x: fuzz.ratio(x,item['name'])).max() >= 80:\n",
    "        item['name'] = ingredDf[0][ingredDf[0].apply(lambda x: fuzz.ratio(x,item['name'])).idxmax(axis=0)]\n",
    "        \n",
    "    # for phrase-like ingredients\n",
    "    cleaned_names = list(ingredDf[ingredDf[0].apply(lambda x: True if x in item['name'] else False)][0])\n",
    "    if(cleaned_names):\n",
    "        item['name'] = max(cleaned_names,key=len)\n",
    "\n",
    "    # for eliminating plurality\n",
    "    try:\n",
    "        if p.singular_noun(item['name']):\n",
    "            item['name'] = p.singular_noun(item['name'])\n",
    "    except:\n",
    "        print(item['name'])\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterParsed(item):\n",
    "    if len(item['originalName']) < 3 or 'pan' in item['original']:\n",
    "        return False\n",
    "    elif item['name'] not in ingredList:\n",
    "        print(item['name'])\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredDf = pd.read_csv('ingredList.csv',header=None)\n",
    "ingredList = list(ingredDf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masterIngredientNames = []\n",
    "# masterIngredientDicts = []\n",
    "# IngredientIndex = pd.DataFrame()\n",
    "# newRecipe = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if starting from an existing df\n",
    "# IngredientIndex.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  399\n"
     ]
    }
   ],
   "source": [
    "for i in range(300,400):\n",
    "    clear_output(wait=True)\n",
    "    print(\"index: \", i)\n",
    "    newRecipe = True\n",
    "    \n",
    "    # prepare structures to collect recipe info\n",
    "    ingredientNames = []\n",
    "    ingredientDict = {}\n",
    "    \n",
    "    # get ingredient section, if exists\n",
    "    desc = uploads['snippet.description'][i].lower()\n",
    "    if \"ingredient\" in desc:\n",
    "        section = desc.split(\"ingredient\",1)[1] \n",
    "    else:\n",
    "        print(\"error at index\",i)\n",
    "        masterIngredientDicts.append(ingredientDict)\n",
    "        masterIngredientNames.append(ingredientNames)\n",
    "        continue\n",
    "    \n",
    "    # format out foreign language / some symbols -- account for fractions\n",
    "    formatted = re.sub(r'[^a-zA-Z| |0-9|\\n|,|\\+|\\|.|/|\\(|\\)]', '', section)\n",
    "    formatted = re.sub(r'/[^0-9]', '',formatted)\n",
    "    \n",
    "    # filter out instructional steps\n",
    "    ingredients = re.split('\\n',formatted)\n",
    "    ingredients = list(filter(filterOutSteps, ingredients))\n",
    "    newLine = \"\\n\"\n",
    "    ingredients = newLine.join(ingredients)\n",
    "\n",
    "    # break up multi-line ingredients and filter out invalid ones\n",
    "    ingredients = re.split(',|\\n|\\+|\\(|\\)',ingredients)\n",
    "    ingredients = list(map(lambda x: x.strip(),ingredients))\n",
    "    ingredients = list(filter(filterOutIngred, ingredients))\n",
    "    ingredients = newLine.join(ingredients)\n",
    "    \n",
    "    # call spoonacular API to parse ingredients\n",
    "    payload = {'ingredientList': ingredients, 'servings': 1}\n",
    "    response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "    data = response.json()   \n",
    "    \n",
    "    # cleaning\n",
    "    data = list(map(cleanParsed,data))\n",
    "    \n",
    "    # apply another filter here ?? \n",
    "    dataTest = list(filter(filterParsed, data))\n",
    "\n",
    "    # iterate through each entry returned (each ingredient parsed out)\n",
    "    for ingredient in dataTest:\n",
    "        ingredientName = ingredient['name']\n",
    "\n",
    "        # check if ingredient has been used in recipe before (if so, then aggregate)\n",
    "        if ingredientName in ingredientDict.keys():    \n",
    "            unitName = ingredient['unitShort']\n",
    "            amount = ingredient['amount']\n",
    "\n",
    "            if unitName in ingredientDict[ingredientName].keys():\n",
    "                ingredientDict[ingredientName][unitName] += amount\n",
    "            else:\n",
    "                ingredientDict[ingredientName][unitName] = amount\n",
    "       \n",
    "        # if new ingredient, create new entry in recipe\n",
    "        else:\n",
    "            ingredientInfo = dict((k, ingredient[k]) for k in ('amount', 'unitShort'))\n",
    "            ingredientNames.append(ingredientName)\n",
    "\n",
    "            unitName = ingredientInfo['unitShort']\n",
    "            amount = ingredientInfo['amount']\n",
    "\n",
    "            ingredientDict[ingredientName] = dict()\n",
    "            ingredientDict[ingredientName][unitName] = amount\n",
    "          \n",
    "        # update the master ingredient index \n",
    "        if ingredientName not in list(IngredientIndex.index):\n",
    "            IngredientIndex.loc[ingredientName, 'count'] = 1\n",
    "            try:\n",
    "                IngredientIndex.loc[ingredientName, 'aisle'] = ingredient['aisle']\n",
    "            except:\n",
    "                IngredientIndex.loc[ingredientName, 'aisle'] = \"Other\"\n",
    "                \n",
    "        elif newRecipe:\n",
    "            IngredientIndex.loc[ingredientName, 'count'] += 1\n",
    "            newRecipe = False\n",
    "            \n",
    "    masterIngredientDicts.append(ingredientDict)\n",
    "    masterIngredientNames.append(ingredientNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = uploads[:len(masterIngredientNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/Jesse/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "snippet['ingredientDetails'] = masterIngredientDicts\n",
    "snippet['ingredientNames'] = masterIngredientNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = snippet[snippet['ingredientNames'].apply(lambda x: True if len(x)!= 0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IngredientIndex.reset_index(inplace=True)\n",
    "IngredientIndex.columns = ['name','count','aisle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoDf = snippet[['snippet.resourceId.videoId','snippet.publishedAt','snippet.title','snippet.channelTitle','ingredientNames','ingredientDetails']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "videoDf.rename(columns={'snippet.resourceId.videoId':\n",
    "                      'id', 'snippet.publishedAt':'published', 'snippet.title':'title',\n",
    "                      'snippet.channelTitle':'channel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb+srv://janet:janet@cluster0-nnw1z.mongodb.net/desserts?retryWrites=true&w=majority\")\n",
    "db = client.desserts\n",
    "videos = db.videos\n",
    "videos.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x103e7d988>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoDict = videoDf.to_dict(orient = 'records')\n",
    "videos.insert_many(videoDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = db.ingredients\n",
    "ingredients.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x103ec4688>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredientDict = IngredientIndex.to_dict(orient = 'records')\n",
    "ingredients.insert_many(ingredientDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.mongodb.com/manual/reference/operator/aggregation/setIsSubset/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
